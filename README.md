# ğŸ“Š AvaliaÃ§Ã£o Comparativa de LLMs no Apoio CientÃ­fico

Este repositÃ³rio contÃ©m os dados utilizados no estudo sobre a **AvaliaÃ§Ã£o Comparativa de Modelos de Linguagem de Grande Escala (LLMs) no Apoio CientÃ­fico**. O objetivo desta anÃ¡lise Ã© examinar o desempenho de diferentes LLMs em tarefas cientÃ­ficas, considerando mÃ©tricas como **relevÃ¢ncia contextual, coerÃªncia, exatidÃ£o, profundidade analÃ­tica e sensibilidade ao contexto**.

## ğŸ“‚ Estrutura do RepositÃ³rio

- **ğŸ“„ `dados_NEBs_LLMs.xlsx`** â†’ Arquivo contendo as respostas dos LLMs avaliados e sua categorizaÃ§Ã£o com base nas mÃ©tricas estabelecidas.
- **ğŸ“œ `LICENSE`** â†’ LicenÃ§a MIT para permitir o uso aberto dos dados.

## ğŸ“‘ DescriÃ§Ã£o dos Dados

Os dados foram coletados a partir de interaÃ§Ãµes com trÃªs LLMs distintos:

- **ChatGPT (GPT-4o - OpenAI)**
- **Microsoft Copilot**
- **ChatPDF**

Cada modelo foi submetido aos mesmos prompts e artigos cientÃ­ficos, permitindo uma comparaÃ§Ã£o direta dos resultados. As respostas foram analisadas em relaÃ§Ã£o a **cinco dimensÃµes-chave** para determinar seus pontos fortes e fracos no suporte a tarefas cientÃ­ficas.

## ğŸ“Œ Uso dos Dados

Os dados podem ser utilizados para estudos adicionais sobre LLMs em contextos acadÃªmicos e cientÃ­ficos, bem como para o aprimoramento de **tÃ©cnicas de engenharia de prompts**.

## ğŸ“œ LicenÃ§a

Este repositÃ³rio estÃ¡ licenciado sob a **MIT License**. Consulte o arquivo [`LICENSE`](LICENSE) para mais detalhes.

---

ğŸ“¢ **Caso utilize os dados deste repositÃ³rio em sua pesquisa, cite a fonte conforme apropriado.**
